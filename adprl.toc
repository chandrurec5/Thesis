\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Markov Decision Process}{1}
\contentsline {section}{\numberline {1.2}Practical Issues}{2}
\contentsline {section}{\numberline {1.3}Approximate Dynamic Programming}{3}
\contentsline {section}{\numberline {1.4}Linear Function Approximation}{4}
\contentsline {subsection}{\numberline {1.4.1}Projected Bellman Equation}{4}
\contentsline {subsection}{\numberline {1.4.2}Approximate Linear Programming}{5}
\contentsline {section}{\numberline {1.5}Reinforcement Learning}{6}
\contentsline {chapter}{\numberline {2}Markov Decision Processes (MDPs)}{8}
\contentsline {section}{\numberline {2.1}Definition}{8}
\contentsline {section}{\numberline {2.2}Inifinte Horizon Discounted Reward}{8}
\contentsline {section}{\numberline {2.3}Bellman Equation}{9}
\contentsline {section}{\numberline {2.4}Bellman Operator}{10}
\contentsline {section}{\numberline {2.5}Basic Solution Methods}{11}
\contentsline {section}{\numberline {2.6}Curse of Dimentionality}{12}
\contentsline {section}{\numberline {2.7}Value Function Based Approximate Dynamic Programming}{13}
\contentsline {section}{\numberline {2.8}Linear Function Approximation}{14}
\contentsline {section}{\numberline {2.9}Control and Prediction}{14}
\contentsline {chapter}{\numberline {3}Approximate Dynamic Programming in $(\qopname \relax m{min},+)$ linear basis}{15}
\contentsline {section}{\numberline {3.1}Projected Bellman Equation}{15}
\contentsline {section}{\numberline {3.2}Monotone Maps}{17}
\contentsline {section}{\numberline {3.3}$(\qopname \relax m{min},+)$ linear functions}{17}
\contentsline {section}{\numberline {3.4}Fenchel Dual and Projection on Subsemimodules}{18}
\contentsline {section}{\numberline {3.5} Approximate $Q$ Iteration}{19}
\contentsline {section}{\numberline {3.6}Variational Approximate Q Iteration}{20}
\contentsline {section}{\numberline {3.7}Error Analysis}{21}
\contentsline {subsection}{\numberline {3.7.1}Experiment in Grid World}{22}
\contentsline {subsection}{\numberline {3.7.2}The Mountain Car Experiment}{24}
\contentsline {chapter}{\numberline {4}Approximate Linear Program}{28}
\contentsline {section}{\numberline {4.1}Approximate Linear Programming}{28}
\contentsline {section}{\numberline {4.2}Lyanpunov Functions}{30}
\contentsline {section}{\numberline {4.3}Constraint sampling}{30}
\contentsline {chapter}{\numberline {5}Generalized Reduced Linear Program}{33}
\contentsline {section}{\numberline {5.1}Generalized Reduced Linear Program}{33}
\contentsline {section}{\numberline {5.2}Least Upper Bound Projection}{34}
\contentsline {section}{\numberline {5.3}Approximate Least Upper Bound Projection}{37}
\contentsline {section}{\numberline {5.4}A simple bound}{39}
\contentsline {section}{\numberline {5.5}Improved Bounds}{41}
\contentsline {section}{\numberline {5.6}Discussion}{44}
\contentsline {subsection}{\numberline {5.6.1}On Error Terms}{44}
\contentsline {subsection}{\numberline {5.6.2}On Constraint Reduction and Approximation}{45}
\contentsline {subsection}{\numberline {5.6.3}Numerical Illustration}{46}
\contentsline {subsection}{\numberline {5.6.4}Reinforcement Learning}{48}
\contentsline {section}{\numberline {5.7}Conclusion}{48}
\contentsline {chapter}{\numberline {6}Stochastic Approximation and Reinforcement Learning}{50}
\contentsline {section}{\numberline {6.1}Lack of Model Information}{50}
\contentsline {section}{\numberline {6.2}Reinforcement Learning}{50}
\contentsline {section}{\numberline {6.3}Two Timescale Stochastic Approximation}{50}
\contentsline {section}{\numberline {6.4}Actor Critic Algorithms}{50}
\contentsline {chapter}{\numberline {7}Stability of Iterates in Two Timescale Stochastic Approximation}{51}
\contentsline {section}{\numberline {7.1}Introduction}{51}
\contentsline {section}{\numberline {7.2}Results for the Scaled ODE}{54}
\contentsline {section}{\numberline {7.3}Stability of Two Timescale Stochastic Approximation Algorithms}{59}
\contentsline {subsection}{\numberline {7.3.1}Faster Timescale Results}{60}
\contentsline {subsection}{\numberline {7.3.2}Slower Timescale Analysis}{64}
\contentsline {section}{\numberline {7.4}An Application in Reinforcement Learning}{67}
\contentsline {section}{\numberline {7.5}Conclusions}{73}
\contentsline {section}{\numberline {7.6}Appendix}{73}
\contentsline {subsection}{\numberline {7.6.1}Gronwall Inequalities}{73}
