\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Markov Decision Processes}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Practical Issues}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Approximate Dynamic Programming}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Linear Function Approximation}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Projected Bellman Equation}{5}}
\citation{BertB}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Approximate Linear Programming}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Reinforcement Learning}{8}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Markov Decision Processes (MDPs)}{10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Definition}{10}}
\citation{BertB,Puter}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Inifinte Horizon Discounted Reward}{11}}
\citation{BertB}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Bellman Equation}{12}}
\newlabel{bell}{{2.1}{12}}
\newlabel{bellval}{{2.1a}{12}}
\newlabel{bellpol}{{2.1b}{12}}
\newlabel{subpol}{{2.4}{12}}
\newlabel{bellactval}{{4}{12}}
\citation{BertB}
\citation{BertB}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Bellman Operator}{13}}
\newlabel{maxnorm}{{5}{13}}
\newlabel{uniquesol}{{1}{13}}
\newlabel{monotone}{{6}{13}}
\newlabel{shift}{{7}{13}}
\citation{BertB}
\newlabel{mdplp}{{2.8}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Basic Solution Methods}{14}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Value Iteration (VI)}}{14}}
\newlabel{valiter}{{1}{14}}
\citation{BertB}
\citation{lspi,lspe,ALP,wang2014approximate}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Policy Iteration (PI)}}{15}}
\newlabel{politer}{{2}{15}}
\newlabel{mdplp}{{2.9}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Curse of Dimentionality}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Value Function Based Approximate Dynamic Programming}{16}}
\newlabel{subopt}{{8}{16}}
\newlabel{top}{{2.11}{16}}
\newlabel{bot}{{2.12}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Linear Function Approximation}{18}}
\citation{dpchapter}
\citation{dpchapter}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Approximate Dynamic Programming in $(\qopname  \relax m{min},+)$ linear basis}{19}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Projected Bellman Equation}{20}}
\newlabel{pbelong}{{3.1}{20}}
\newlabel{pbe}{{3.2}{20}}
\newlabel{errbnd}{{3.3}{20}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Approximate Policy Iteration (API)}}{21}}
\newlabel{appeval}{{3}{21}}
\newlabel{appoliter}{{3}{21}}
\newlabel{pgapi}{{9}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}$(\qopname  \relax m{min},+)$ linear functions}{21}}
\newlabel{semiring}{{3.2}{21}}
\citation{akian,Gaubert,mc2009,gaubert2011}
\citation{akian,cohen1996kernels,Gaubert}
\newlabel{smproj}{{3.4}{22}}
\newlabel{projminpbasic}{{3.5}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Fenchel Dual and Projection on Subsemimodules}{23}}
\newlabel{fenchel}{{3.3}{23}}
\newlabel{FT}{{3.6}{23}}
\newlabel{FFT}{{3.7}{23}}
\newlabel{FTRR}{{3.8}{23}}
\newlabel{ST}{{3.9}{23}}
