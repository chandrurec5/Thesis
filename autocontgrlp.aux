\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{BMSTAB}
\@writefile{toc}{\contentsline {section}{\numberline {I}Markov Decision Processes}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Practical Issues}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Approximate Dynamic Programming}{3}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Linear Function Approximation}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Projected Bellman Equation}{4}{subsection.4.1}}
\citation{BertB}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Approximate Linear Programming}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Reinforcement Learning}{7}{section.5}}
\citation{BertB,Puter}
\citation{BertB,Puter}
\citation{BertB}
\newlabel{bell}{{1}{9}{Reinforcement Learning}{equation.5.1}{}}
\newlabel{bellval}{{1a}{9}{Reinforcement Learning}{equation.5.1}{}}
\newlabel{bellpol}{{1b}{9}{Reinforcement Learning}{equation.5.2}{}}
\newlabel{subpol}{{4}{9}{Reinforcement Learning}{equation.5.4}{}}
\newlabel{bellactval}{{4}{9}{Reinforcement Learning}{theorem.4}{}}
\citation{BertB}
\citation{BertB}
\citation{BertB}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Properties of $T$}{10}{subsection.5.1}}
\newlabel{maxnorm}{{5}{10}{Properties of $T$}{theorem.5}{}}
\newlabel{uniquesol}{{1}{10}{Properties of $T$}{corollary.1}{}}
\newlabel{monotone}{{6}{10}{Properties of $T$}{theorem.6}{}}
\newlabel{shift}{{7}{10}{Properties of $T$}{theorem.7}{}}
\newlabel{mdplp}{{8}{10}{Properties of $T$}{equation.5.8}{}}
\citation{lspi,lspe,ALP,wang2014approximate}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Approximate Dynamic Programming}{11}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Value-Function based ADP}{11}{subsection.6.1}}
\newlabel{subopt}{{8}{11}{Value-Function based ADP}{theorem.8}{}}
\citation{dpchapter}
\citation{dpchapter}
\citation{ALP}
\citation{ALP,CS,CST}
\citation{CS}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}Linear Function Approximation}{12}{subsection.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Approximate Linear Programming}{13}{section.7}}
\newlabel{mdplpshort}{{10}{13}{Approximate Linear Programming}{equation.7.10}{}}
\newlabel{shortalter}{{11}{13}{Approximate Linear Programming}{equation.7.11}{}}
\newlabel{alp}{{13}{13}{Approximate Linear Programming}{equation.7.13}{}}
\citation{ALP}
\citation{ALP}
\newlabel{one}{{1}{14}{Approximate Linear Programming}{assumption.1}{}}
\newlabel{probdist}{{2}{14}{Approximate Linear Programming}{assumption.2}{}}
\newlabel{lyap}{{3}{14}{Approximate Linear Programming}{assumption.3}{}}
\newlabel{modlone}{{11}{14}{Approximate Linear Programming}{theorem.11}{}}
\newlabel{modnorm}{{12}{14}{Approximate Linear Programming}{theorem.12}{}}
\newlabel{restateval}{{13}{14}{Approximate Linear Programming}{theorem.13}{}}
\citation{ALP}
\citation{CS}
\citation{ALP}
\citation{SALP}
\citation{CST}
\citation{SALP}
\citation{CS}
\citation{CS}
\newlabel{restatepol}{{14}{15}{Approximate Linear Programming}{theorem.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Constraint sampling}{15}{section.8}}
\newlabel{rlp}{{19}{15}{Constraint sampling}{equation.8.19}{}}
\newlabel{csampmat}{{15}{15}{Constraint sampling}{theorem.15}{}}
\newlabel{rlpshort}{{21}{15}{Constraint sampling}{equation.8.21}{}}
\citation{CS}
\newlabel{sampdist}{{16}{16}{Constraint sampling}{theorem.16}{}}
\newlabel{csresult}{{17}{16}{Constraint sampling}{theorem.17}{}}
\citation{CS}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Generalized Reduced Linear Program}{17}{section.9}}
\newlabel{grlp}{{25}{17}{Generalized Reduced Linear Program}{equation.9.25}{}}
\newlabel{wassump}{{4}{18}{Generalized Reduced Linear Program}{assumption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {X}Least Upper Bound Projection}{18}{section.10}}
\newlabel{sec:lubp}{{X}{18}{Least Upper Bound Projection}{section.10}{}}
\newlabel{lubpop}{{18}{18}{Least Upper Bound Projection}{theorem.18}{}}
\newlabel{gamdef}{{26}{18}{Least Upper Bound Projection}{equation.10.26}{}}
\newlabel{lubplp}{{27}{18}{Least Upper Bound Projection}{equation.10.27}{}}
\newlabel{bestproj}{{19}{19}{Least Upper Bound Projection}{theorem.19}{}}
\newlabel{bestbnd}{{20}{19}{Least Upper Bound Projection}{theorem.20}{}}
\newlabel{gmonotone}{{21}{19}{Least Upper Bound Projection}{theorem.21}{}}
\newlabel{lpsol}{{22}{20}{Least Upper Bound Projection}{theorem.22}{}}
\newlabel{gshift}{{23}{20}{Least Upper Bound Projection}{theorem.23}{}}
\newlabel{gmaxcontra}{{24}{20}{Least Upper Bound Projection}{theorem.24}{}}
\newlabel{ineq}{{31}{20}{Least Upper Bound Projection}{equation.10.31}{}}
\newlabel{ineq}{{32}{20}{Least Upper Bound Projection}{equation.10.32}{}}
\newlabel{pvi}{{33}{20}{Least Upper Bound Projection}{equation.10.33}{}}
\newlabel{gfp}{{25}{20}{Least Upper Bound Projection}{theorem.25}{}}
\newlabel{relation1}{{26}{20}{Least Upper Bound Projection}{theorem.26}{}}
\newlabel{lineq}{{34}{21}{Least Upper Bound Projection}{equation.10.34}{}}
\newlabel{fxpres}{{27}{21}{Least Upper Bound Projection}{theorem.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {XI}Approximate Least Upper Bound Projection}{21}{section.11}}
\newlabel{sec:alubp}{{XI}{21}{Approximate Least Upper Bound Projection}{section.11}{}}
\newlabel{alubpop}{{28}{21}{Approximate Least Upper Bound Projection}{theorem.28}{}}
\newlabel{tgamdef}{{37}{21}{Approximate Least Upper Bound Projection}{equation.11.37}{}}
\newlabel{alubplp}{{38}{22}{Approximate Least Upper Bound Projection}{equation.11.38}{}}
\newlabel{tgmonotone}{{29}{22}{Approximate Least Upper Bound Projection}{theorem.29}{}}
\newlabel{tgshift}{{30}{22}{Approximate Least Upper Bound Projection}{theorem.30}{}}
\newlabel{tgmaxcontra}{{31}{22}{Approximate Least Upper Bound Projection}{theorem.31}{}}
\newlabel{apvi}{{39}{22}{Approximate Least Upper Bound Projection}{equation.11.39}{}}
\newlabel{relation2}{{32}{22}{Approximate Least Upper Bound Projection}{theorem.32}{}}
\newlabel{mt1}{{33}{23}{Approximate Least Upper Bound Projection}{theorem.33}{}}
\newlabel{cmt1}{{3}{23}{Approximate Least Upper Bound Projection}{corollary.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {XII}A simple bound}{23}{section.12}}
\newlabel{srw}{{34}{23}{A simple bound}{theorem.34}{}}
\newlabel{grlpeqprog}{{45}{23}{A simple bound}{equation.12.45}{}}
\newlabel{mt2}{{35}{24}{A simple bound}{theorem.35}{}}
\newlabel{cmt2}{{4}{24}{A simple bound}{corollary.4}{}}
\newlabel{finalbnd}{{49}{24}{A simple bound}{equation.12.49}{}}
\citation{ALP}
\@writefile{toc}{\contentsline {section}{\numberline {XIII}Improved Bounds}{25}{section.13}}
\newlabel{sec:improv}{{XIII}{25}{Improved Bounds}{section.13}{}}
\newlabel{bestbndmn}{{36}{25}{Improved Bounds}{theorem.36}{}}
\newlabel{gshiftmn}{{37}{25}{Improved Bounds}{theorem.37}{}}
\newlabel{gmaxcontramn}{{38}{25}{Improved Bounds}{theorem.38}{}}
\newlabel{ineq}{{51}{25}{Improved Bounds}{equation.13.51}{}}
\newlabel{ineq}{{52}{25}{Improved Bounds}{equation.13.52}{}}
\newlabel{hgmaxcontramn}{{5}{25}{Improved Bounds}{corollary.5}{}}
\newlabel{cmt1mn}{{39}{25}{Improved Bounds}{theorem.39}{}}
\newlabel{restate}{{40}{26}{Improved Bounds}{theorem.40}{}}
\newlabel{mt2mn}{{41}{26}{Improved Bounds}{theorem.41}{}}
\newlabel{cmt2mn}{{42}{26}{Improved Bounds}{theorem.42}{}}
\newlabel{finalbndmn}{{58}{26}{Improved Bounds}{equation.13.58}{}}
\newlabel{polthe}{{43}{27}{Improved Bounds}{theorem.43}{}}
\newlabel{polthebnd}{{59}{27}{Improved Bounds}{equation.13.59}{}}
\newlabel{polderv}{{60}{27}{Improved Bounds}{equation.13.60}{}}
\newlabel{loose1}{{62}{27}{Improved Bounds}{equation.13.62}{}}
\newlabel{loose2}{{63}{27}{Improved Bounds}{equation.13.63}{}}
\citation{ALP}
\citation{CS}
\@writefile{toc}{\contentsline {section}{\numberline {XIV}Discussion}{28}{section.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XIV-A}}On Error Terms}{28}{subsection.14.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XIV-B}}On Constraint Reduction and Approximation}{28}{subsection.14.2}}
\citation{ALP,CST,SALP}
\citation{dolgov}
\newlabel{st}{{44}{29}{On Constraint Reduction and Approximation}{theorem.44}{}}
\newlabel{sampexp}{{64}{29}{On Constraint Reduction and Approximation}{equation.14.64}{}}
\newlabel{lag}{{65}{29}{On Constraint Reduction and Approximation}{equation.14.65}{}}
\newlabel{lag2}{{66}{29}{On Constraint Reduction and Approximation}{equation.14.66}{}}
\citation{ALP}
\citation{ALP}
\citation{ALP}
\citation{CS}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XIV-C}}Numerical Illustration}{30}{subsection.14.3}}
\newlabel{wdes}{{67}{31}{Numerical Illustration}{equation.14.67}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Shows values of Error Terms for $Q_L$.}}{31}{table.1}}
\newlabel{pref}{{I}{31}{Shows values of Error Terms for $Q_L$}{table.1}{}}
\citation{CST,CS}
\citation{ALP-Bor}
\citation{ALP-Bor}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Shows performance metrics for $Q_L$. Here $||J^*||_{1,c}=-439.26$ for $\zeta =0.9$ and $||J^*||_{1,c}=-2.0603e+04$ for $\zeta =0.999$ and a random policy yields a total reward of $-1.2661e+03 $.}}{32}{table.2}}
\newlabel{pref}{{II}{32}{Shows performance metrics for $Q_L$. Here $||J^*||_{1,c}=-439.26$ for $\zeta =0.9$ and $||J^*||_{1,c}=-2.0603e+04$ for $\zeta =0.999$ and a random policy yields a total reward of $-1.2661e+03 $}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XIV-D}}Reinforcement Learning}{32}{subsection.14.4}}
\@writefile{toc}{\contentsline {section}{\numberline {XV}Conclusion}{32}{section.15}}
\bibstyle{plain}
\bibdata{ref.bib}
