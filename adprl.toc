\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Markov Decision Processes}{1}
\contentsline {section}{\numberline {1.2}Practical Issues}{2}
\contentsline {section}{\numberline {1.3}Approximate Dynamic Programming}{3}
\contentsline {section}{\numberline {1.4}Linear Function Approximation}{4}
\contentsline {subsection}{\numberline {1.4.1}Projected Bellman Equation}{5}
\contentsline {subsection}{\numberline {1.4.2}Approximate Linear Programming}{6}
\contentsline {section}{\numberline {1.5}Reinforcement Learning}{8}
\contentsline {chapter}{\numberline {2}Markov Decision Processes (MDPs)}{10}
\contentsline {section}{\numberline {2.1}Definition}{10}
\contentsline {section}{\numberline {2.2}Inifinte Horizon Discounted Reward}{11}
\contentsline {section}{\numberline {2.3}Bellman Equation}{12}
\contentsline {section}{\numberline {2.4}Bellman Operator}{13}
\contentsline {section}{\numberline {2.5}Basic Solution Methods}{14}
\contentsline {section}{\numberline {2.6}Curse of Dimentionality}{16}
\contentsline {section}{\numberline {2.7}Value Function Based Approximate Dynamic Programming}{16}
\contentsline {section}{\numberline {2.8}Linear Function Approximation}{18}
\contentsline {chapter}{\numberline {3}Approximate Dynamic Programming in $(\qopname \relax m{min},+)$ linear basis}{19}
\contentsline {section}{\numberline {3.1}Projected Bellman Equation}{20}
\contentsline {section}{\numberline {3.2}$(\qopname \relax m{min},+)$ linear functions}{21}
\contentsline {section}{\numberline {3.3}Fenchel Dual and Projection on Subsemimodules}{23}
\contentsline {section}{\numberline {3.4} Approximate $Q$ Iteration}{25}
\contentsline {section}{\numberline {3.5}Variational Approximate Q Iteration}{26}
\contentsline {section}{\numberline {3.6}Error Analysis}{27}
\contentsline {subsection}{\numberline {3.6.1}Experiment in Grid World}{28}
\contentsline {subsection}{\numberline {3.6.2}The Mountain Car Experiment}{31}
\contentsline {chapter}{\numberline {4}Approximate Linear Program}{35}
\contentsline {section}{\numberline {4.1}Approximate Linear Programming}{35}
\contentsline {section}{\numberline {4.2}Lyanpunov Functions}{38}
\contentsline {section}{\numberline {4.3}Constraint sampling}{38}
\contentsline {chapter}{\numberline {5}Generalized Reduced Linear Program}{41}
\contentsline {section}{\numberline {5.1}Generalized Reduced Linear Program}{41}
\contentsline {section}{\numberline {5.2}Least Upper Bound Projection}{43}
\contentsline {section}{\numberline {5.3}Approximate Least Upper Bound Projection}{47}
\contentsline {section}{\numberline {5.4}A simple bound}{49}
\contentsline {section}{\numberline {5.5}Improved Bounds}{51}
\contentsline {section}{\numberline {5.6}Discussion}{55}
\contentsline {subsection}{\numberline {5.6.1}On Error Terms}{55}
\contentsline {subsection}{\numberline {5.6.2}On Constraint Reduction and Approximation}{56}
\contentsline {subsection}{\numberline {5.6.3}Numerical Illustration}{58}
\contentsline {subsection}{\numberline {5.6.4}Reinforcement Learning}{60}
\contentsline {section}{\numberline {5.7}Conclusion}{61}
\contentsline {chapter}{\numberline {6}Stochastic Approximation and Reinforcement Learning}{62}
\contentsline {chapter}{\numberline {7}Stability of Iterates in Two Timescale Stochastic Approximation}{63}
\contentsline {section}{\numberline {7.1}Introduction}{63}
\contentsline {section}{\numberline {7.2}Results for the Scaled ODE}{67}
\contentsline {section}{\numberline {7.3}Stability of Two Timescale Stochastic Approximation Algorithms}{73}
\contentsline {subsection}{\numberline {7.3.1}Faster Timescale Results}{74}
\contentsline {subsection}{\numberline {7.3.2}Slower Timescale Analysis}{79}
\contentsline {section}{\numberline {7.4}An Application in Reinforcement Learning}{83}
\contentsline {section}{\numberline {7.5}Conclusions}{90}
\contentsline {section}{\numberline {7.6}Appendix}{91}
\contentsline {subsection}{\numberline {7.6.1}Gronwall Inequalities}{91}
