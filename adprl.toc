\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Markov Decision Processes}{1}
\contentsline {section}{\numberline {1.2}Practical Issues}{2}
\contentsline {section}{\numberline {1.3}Approximate Dynamic Programming}{3}
\contentsline {section}{\numberline {1.4}Linear Function Approximation}{4}
\contentsline {subsection}{\numberline {1.4.1}Projected Bellman Equation}{5}
\contentsline {subsection}{\numberline {1.4.2}Approximate Linear Programming}{6}
\contentsline {section}{\numberline {1.5}Reinforcement Learning}{8}
\contentsline {chapter}{\numberline {2}Markov Decision Processes (MDPs)}{10}
\contentsline {section}{\numberline {2.1}Definition}{10}
\contentsline {section}{\numberline {2.2}Inifinte Horizon Discounted Reward}{11}
\contentsline {section}{\numberline {2.3}Bellman Equation}{12}
\contentsline {section}{\numberline {2.4}Bellman Operator}{13}
\contentsline {section}{\numberline {2.5}Basic Solution Methods}{14}
\contentsline {section}{\numberline {2.6}Curse of Dimentionality}{16}
\contentsline {section}{\numberline {2.7}Value Function Based Approximate Dynamic Programming}{16}
\contentsline {section}{\numberline {2.8}Linear Function Approximation}{18}
\contentsline {chapter}{\numberline {3}Approximate Dynamic Programming in $(\qopname \relax m{min},+)$ linear basis}{19}
\contentsline {section}{\numberline {3.1}Projected Bellman Equation}{20}
\contentsline {chapter}{\numberline {4}Approximate Linear Program}{22}
\contentsline {section}{\numberline {4.1}Approximate Linear Programming}{22}
\contentsline {section}{\numberline {4.2}Lyanpunov Functions}{25}
\contentsline {section}{\numberline {4.3}Constraint sampling}{25}
\contentsline {chapter}{\numberline {5}Generalized Reduced Linear Program}{28}
\contentsline {section}{\numberline {5.1}Generalized Reduced Linear Program}{28}
\contentsline {section}{\numberline {5.2}Least Upper Bound Projection}{30}
\contentsline {section}{\numberline {5.3}Approximate Least Upper Bound Projection}{34}
\contentsline {section}{\numberline {5.4}A simple bound}{36}
\contentsline {section}{\numberline {5.5}Improved Bounds}{38}
\contentsline {section}{\numberline {5.6}Discussion}{42}
\contentsline {subsection}{\numberline {5.6.1}On Error Terms}{42}
\contentsline {subsection}{\numberline {5.6.2}On Constraint Reduction and Approximation}{43}
\contentsline {subsection}{\numberline {5.6.3}Numerical Illustration}{45}
\contentsline {subsection}{\numberline {5.6.4}Reinforcement Learning}{47}
\contentsline {section}{\numberline {5.7}Conclusion}{48}
\contentsline {chapter}{\numberline {6}Stochastic Approximation and Reinforcement Learning}{49}
\contentsline {chapter}{\numberline {7}Stability of Iterates in Two Timescale Stochastic Approximation}{50}
\contentsline {section}{\numberline {7.1}Introduction}{50}
\contentsline {section}{\numberline {7.2}Results for the Scaled ODE}{54}
\contentsline {section}{\numberline {7.3}Stability of Two Timescale Stochastic Approximation Algorithms}{60}
\contentsline {subsection}{\numberline {7.3.1}Faster Timescale Results}{61}
\contentsline {subsection}{\numberline {7.3.2}Slower Timescale Analysis}{66}
\contentsline {section}{\numberline {7.4}An Application in Reinforcement Learning}{70}
\contentsline {section}{\numberline {7.5}Conclusions}{77}
\contentsline {section}{\numberline {7.6}Appendix}{78}
\contentsline {subsection}{\numberline {7.6.1}Gronwall Inequalities}{78}
